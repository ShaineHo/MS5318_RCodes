---
title: "Lec10"
author: "HO Yin Shan"
date: "2023-03-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)
library(tidyverse)
library(ggfortify)
```


```{r}
subprime1 <- read_csv("subprime1.csv")
```

# Lec9 (13th Slides p18)

Q1. Examine the relationship between each pair of variables numerically and visually.

```{r}
cor(subprime1)
```

```{r}
plot(subprime1)
```
Q2. Fit a multiple regression model using all the variables to predict APR. Name the model g. Write down the fitted linear model.

```{r}
g <- lm(APR ~ LTV + FICO + `Stated Income` + `Home Value`, data = subprime1)
summary(g)
```

APR = 23.7253652432 - 1.5888429952* LTV - 0.0184317607* FICO + 0.0004032124* Stated Income - 0.0007520823 *Home Value


Q3. Make a residual plot of **𝑒** on **𝑌_bar**.

```{r}
plot(g$fitted, g$residuals)
```

Q4. Make a residual plot of **𝑒** on **FICO**.

```{r}
plot(subprime1$FICO, g$residuals)
```
Q5. Make a normal quantile plot of residuals (including the straight line) 

```{r}
#method 1
autoplot(g)

#method 2 
qqnorm(g$residuals)
qqline(g$residuals)
```

Q6. Make a histogram of the residuals.

```{r}
hist(g$residuals)
```
Q7. Does the four variables together explain statistically significant variation in APR?

```{r}
summary(g)
# check F statistics (questions asked 4 variables together)
```

p-value: < 2.2e-16, for the whole model **(four variables together)**, the model is statistically significant.


Q8. Is the effect of *Stated.Income* significant, given the values of the other three variables?

No, because p-value is 0.9036.



# Lec10

```{r}
capm <- read_csv("capm.csv")
```

```{r}
attach(capm)
g1 <- lm(`Sony Change` ~ `Market Change`, data = capm) 
summary(g1)
```

```{r}
autoplot(g1)
```

```{r}
#win.graph() for windows only

# run thisall together in rmd (mac)
quartz()
plot(`Market Change`, `Sony Change`)
abline(g1$coefficients)
identify(`Market Change`, `Sony Change`)
```

```{r}
g2 = lm(Sony.Change~Market.Change, data=capm1[-60,]) 
g3 = lm(Sony.Change~Market.Change, data=capm1[-100,])
abline(g2$coefficients, col="red")


abline(g3$coefficients, col="green")
g4 = lm(Sony.Change~Market.Change, data=capm1[-c(60,100),])
abline(g4$coefficients, col="blue")

quartz()
plot(Market.Change, Sony.Change)
abline(g1$coefficients, col ="black")
abline(g2$coefficients, col="red")
abline(g3$coefficients, col="green")
abline(g4$coefficients, col="blue")

```

```{r}
library(car)
model1 = lm(Sony.Change~Market.Change+Dow.Change+Small.Big+High.Low)
summary(model1)

vif(model1)
```

```{r}
model2 = lm(Sony.Change~Dow.Change+Small.Big+High.Low)
summary(model2)
vif(model2)
```

```{r}
model3 = lm(Sony.Change~Market.Change+Small.Big+High.Low)
summary(model3)

vif(model3)
```



```{r}
retail <- read_csv("retail_prof.csv")
```

Q1. Calculate the correlation matrix

```{r}
retail1 <- retail %>% 
  select(-Location)

cor(retail1)
```

Q2. Make a scatterplot matrix.  Pay attention to possibly redundant variables.  

```{r}
plot(retail1)
```
Q3. Fit a multiple regression model with all the six predictors

```{r}
retail2 <- retail1 %>% 
  select(-Income)

model = lm(Profit~., data = retail2)
summary(model)
```

Q4. Calculate VIFs for all the predictors.  

```{r}
vif(model)
```

Q5. How would you adjust the model?  Track how the R-square changes when you drop predictors.  

```{r}
model_1 = lm(Profit ~ `Disposable Income` + `Birth Rate` + `Soc Security` +  `CV Death`, data = retail2)
summary(model_1)
vif(model_1)
```

```{r}
model_2 = lm(Profit ~ `Disposable Income` + `Birth Rate` + `Soc Security` +  `65 or Older`, data = retail2)
summary(model_2)
vif(model_2)
```

```{r}
model_3 = lm(Profit ~ `Disposable Income` +  +  `CV Death`, data = retail2)
summary(model_3)
vif(model_3)
```

```{r}
model_3 = lm(Profit ~ `Disposable Income` + `Birth Rate`   +  `CV Death` +  `65 or Older` , data = retail2)
summary(model_3)
vif(model_3)

```

Ans: Remove Social security from comparing R-squared.
